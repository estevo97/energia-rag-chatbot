import gradio as gr
from openai import OpenAI
from dotenv import load_dotenv
from src.rag import retrieve_relevant_context

load_dotenv()
client = OpenAI()

# -----------------------------
# Historial global (solo chat real). Este historial es el que se env칤a al modelo GPT para mantener coherencia. Gradio no lo usa, s칩lo lo usa OpenAI.
# -----------------------------
history = [
    {"role": "system", "content": "Eres un asistente experto en energ칤a."}
]

# -----------------------------
# Funci칩n principal del chat
# -----------------------------
def rag_response(message, chat_history, modo_rag):
    global history # Esta funci칩n deber치 usar y modificar la variable history que est치 definida afuera.

    # Recuperaci칩n RAG
    context = retrieve_relevant_context(message, k=5)

    # Modo SOLO RAG sin contexto. chat_history es el historial visual para la interfaz de Gradio.
    if modo_rag == "Solo RAG" and context is None:
        bot_msg = "No se encontr칩 informaci칩n relevante en los documentos."
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": bot_msg})
        chat_history.append({"role": "user", "content": message})
        chat_history.append({"role": "assistant", "content": bot_msg})
        return chat_history
    
    # Else
    # Prompt para el modelo (NO se guarda en historial)
    full_prompt = (
        f"Pregunta del usuario:\n{message}\n\n"
        f"Contexto recuperado:\n{context}\n\n"
        "Responde de forma clara y precisa."
    )

    # Guardar mensaje del usuario en historial
    history.append({"role": "user", "content": message})

    # Llamada a OpenAI
    messages_to_send = [
        history[0],  # system
        *history[1:-1],  # todo lo anterior excepto el 칰ltimo user que vamos a reemplazar
        {"role": "user", "content": full_prompt}
    ]

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages_to_send
    )

    answer = completion.choices[0].message.content

    # Guardar en historial real
    history.append({"role": "assistant", "content": answer})

    # Mostrar en Gradio
    chat_history.append({"role": "user", "content": message})
    chat_history.append({"role": "assistant", "content": answer})
    return chat_history


# -----------------------------
# Interfaz Gradio
# -----------------------------
def build_interface():
    with gr.Blocks(theme="soft") as demo:
        gr.Markdown("# 游댋 Chatbot RAG sobre Energ칤a")

        modo_rag = gr.Radio(
            ["H칤brido (RAG + Modelo)", "Solo RAG"],
            value="H칤brido (RAG + Modelo)",
            label="Modo"
        )

        chatbot = gr.Chatbot(height=400, type="messages")
        msg = gr.Textbox(label="Escribe tu pregunta:")
        clear = gr.Button("Limpiar chat")

        msg.submit(
            rag_response,
            inputs=[msg, chatbot, modo_rag],
            outputs=chatbot
        )

        def clear_all():
            global history
            history = [history[0]]  # reset al system only
            return []

        clear.click(clear_all, None, chatbot)

    return demo


if __name__ == "__main__":
    demo = build_interface()
    demo.launch()